
[meta]
results_dir = "/afs/cern.ch/user/a/ayeagle/H_mumu/Studies/DNN/results"
use_cuda = true

[dataloader]
# Events selection
additional_cut = '(VBF_JetVeto) & (Signal_Fit)'
# Event splitting
valid_size = 0.20
test_size = 0.40
# Target type
columns_config = '/afs/cern.ch/user/a/ayeagle/H_mumu/Studies/DNN/ds_setup/general.yaml'
signal_types = ['VBFH']
classification = 'binary'      # Binary or multiclass
# Reweigh/rebalance options
uniform_train_weight = false       # If true, all train weights (prenorm) = 1
zero_negative_weights = true       # Remove the effect of negative weights for training only
equalize_class_weights = false     # Sets each class weight to be equal (training only!)
renorm_inputs = 'gauss'            # Apply some scaling/renorm to the input columns. Can be 'no', 'linear', or 'gauss'
downsample_upweight = false        # Whether or not to downsample majority classes
target_ratio = 10                  # New N_{majority_class}/N_{minority_class} ratio (if using downsample)


[network]  
# Hidden layers only
# Input layer size pulled from the used columns
layer_list = [50, 50, 50, 50]
dropout = 0.0

[training]
# batch_size = 0 means use the whole set (1 batch per epoch)
batch_size = 300
epochs = 10
early_stop = true
early_threshold = 0
patience = 100

[optimizer]
algo = "Adam"   # Currently, SGD and Adam are supported
lr = 1e-05
weight_decay = 0
#momentum = 0.7
#dampening = 0.2

[testing]
# Number of bins for all histograms
n_bins = 16


